import 'dart:io';
import 'dart:math';
import 'dart:typed_data';
import 'package:image/image.dart' as img; // Resim iÅŸleme kÃ¼tÃ¼phanesi
import 'package:tflite_flutter/tflite_flutter.dart'; // AI Motoru
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:cloud_firestore/cloud_firestore.dart';

class FaceService {
  Interpreter? _interpreter;
  final FirebaseFirestore _firestore = FirebaseFirestore.instance;

  // --- AYARLAR ---
  // MobileFaceNet modeli 112x112 piksel resim ister.
  static const int INPUT_SIZE = 112; 
  
  // EÅÄ°K DEÄERÄ° (THRESHOLD) Ã‡OK Ã–NEMLÄ°:
  // Eski kodundaki 0.08 Ã§ok dÃ¼ÅŸÃ¼ktÃ¼ Ã§Ã¼nkÃ¼ sadece 5 tane oran vardÄ±.
  // Åimdi 192 tane sayÄ± kÄ±yaslÄ±yoruz. Bu yÃ¼zden mesafe doÄŸal olarak artar.
  // 0.7 ile 1.0 arasÄ± idealdir.
  // 0.8 -> Dengeli
  // 0.6 -> Ã‡ok sÄ±kÄ± (Ä°kizi bile ayÄ±rÄ±r ama seni bazen tanÄ±maz)
  // 1.2 -> GevÅŸek (Herkesi sen sanabilir)
  static const double THRESHOLD = 0.45; 

  /// Servisi baÅŸlatÄ±r ve Yapay Zeka modelini yÃ¼kler
  Future<void> initialize() async {
    try {
      // Model dosyasÄ±nÄ±n assets klasÃ¶rÃ¼nde olduÄŸundan emin ol!
      // Dosya adÄ±: mobilefacenet.tflite
      _interpreter = await Interpreter.fromAsset('assets/mobilefacenet.tflite');
      print("âœ… TFLite Face Model BaÅŸarÄ±yla YÃ¼klendi.");
    } catch (e) {
      print("âŒ Model yÃ¼klenirken hata oluÅŸtu: $e");
      print("LÃ¼tfen assets/mobilefacenet.tflite dosyasÄ±nÄ± kontrol edin.");
    }
  }

  /// 1. YÃ¼zden 192 boyutlu sayÄ±sal imza (embedding) Ã¼retir
  Future<List<double>> getFaceEmbedding(String imagePath, Face face) async {
    if (_interpreter == null) await initialize();

    // 1. Resmi dosyadan oku
    File imageFile = File(imagePath);
    Uint8List imageBytes = await imageFile.readAsBytes();
    img.Image? originalImage = img.decodeImage(imageBytes);

    if (originalImage == null) return [];

    // 2. YÃ¼zÃ¼ resimden kesip al (Crop)
    int x = face.boundingBox.left.toInt();
    int y = face.boundingBox.top.toInt();
    int w = face.boundingBox.width.toInt();
    int h = face.boundingBox.height.toInt();

    // SÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±na taÅŸmayÄ± engelle (Crash olmamasÄ± iÃ§in)
    x = max(0, x);
    y = max(0, y);
    w = min(w, originalImage.width - x);
    h = min(h, originalImage.height - y);

    img.Image croppedFace = img.copyCrop(originalImage, x: x, y: y, width: w, height: h);

    // 3. Resmi modelin istediÄŸi boyuta (112x112) getir
    img.Image resizedFace = img.copyResize(croppedFace, width: INPUT_SIZE, height: INPUT_SIZE);

    // 4. Resmi sayÄ± dizisine Ã§evir (Normalization)
    // Model [1, 112, 112, 3] ÅŸeklinde 4 boyutlu veri bekler.
    var input = _imageToFloatList(resizedFace);

    // 5. Modeli Ã‡alÄ±ÅŸtÄ±r (Inference)
    // Ã‡Ä±ktÄ± olarak [1, 192] boyutunda bir liste verecek.
    var output = List.filled(1 * 192, 0.0).reshape([1, 192]);
    
    _interpreter!.run(input, output);
    List<double> rawEmbedding = List<double>.from(output[0]);

    // HAM VERÄ°YÄ° KONTROL Ä°Ã‡Ä°N YAZDIR (Debug)
    // EÄŸer burada 1.0'dan bÃ¼yÃ¼k sayÄ±lar gÃ¶rÃ¼yorsan normaldir.
    // print("Ham veri Ã¶rneÄŸi: ${rawEmbedding.sublist(0, 5)}");

    // NORMALÄ°ZASYON (Bunu yapmazsak veritabanÄ± bozulur)
    List<double> normalizedEmbedding = _l2Normalize(rawEmbedding);

    // NORMALIZE VERÄ°YÄ° KONTROL ET
    // Buradaki sayÄ±larÄ±n hepsi -1 ile 1 arasÄ±nda OLMALI.
    // print("Normalize veri Ã¶rneÄŸi: ${normalizedEmbedding.sublist(0, 5)}");

    return normalizedEmbedding;
  }

  /// Resmi AI modelinin anlayacaÄŸÄ± Float dizisine Ã§evirir
  List _imageToFloatList(img.Image image) {
    var convertedBytes = Float32List(1 * INPUT_SIZE * INPUT_SIZE * 3);
    var buffer = Float32List.view(convertedBytes.buffer);
    int pixelIndex = 0;

    for (var i = 0; i < INPUT_SIZE; i++) {
      for (var j = 0; j < INPUT_SIZE; j++) {
        var pixel = image.getPixel(j, i);
        // RGB DeÄŸerlerini Normalize et: (DeÄŸer - 128) / 128
        // Bu iÅŸlem renkleri -1 ile 1 arasÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±r.
        buffer[pixelIndex++] = (pixel.r - 128) / 128;
        buffer[pixelIndex++] = (pixel.g - 128) / 128;
        buffer[pixelIndex++] = (pixel.b - 128) / 128;
      }
    }
    return convertedBytes.reshape([1, INPUT_SIZE, INPUT_SIZE, 3]);
  }

  /// 2. VeritabanÄ±ndaki yÃ¼zlerle karÅŸÄ±laÅŸtÄ±rÄ±r
  Future<String?> recognizeFace(List<double> newEmbedding) async {
    try {
      var snapshot = await _firestore.collection('faces').get();
      
      String? bestMatchUser;
      double maxSimilarity = -1.0; // En yÃ¼ksek benzerliÄŸi tutacak deÄŸiÅŸken

      // --- YENÄ° EÅÄ°K DEÄERÄ° ---
      // Cosine Similarity iÃ§in 0.75 - 0.80 arasÄ± idealdir.
      // EÄŸer herkesi sen sanÄ±yorsa bunu 0.80 veya 0.85 yap.
      double currentThreshold = 0.75; 

      for (var doc in snapshot.docs) {
        String userId = doc['userId'];
        List<dynamic> storedData = doc['embedding'];
        List<double> storedEmbedding = storedData.cast<double>();

        // Embedding boyutlarÄ± uyuÅŸmazsa atla
        if (newEmbedding.length != storedEmbedding.length) continue;

        // --- DEÄÄ°ÅEN KISIM BURASI ---
        // ArtÄ±k Ã–klid deÄŸil, Cosine Similarity kullanÄ±yoruz.
        double similarity = _cosineSimilarity(newEmbedding, storedEmbedding);
        
        print("ğŸ” DETAY:");
        print("   -> KayÄ±tlÄ± KiÅŸi: $userId");
        print("   -> Benzerlik PuanÄ±: $similarity"); // 1.0'a ne kadar yakÄ±nsa o kadar iyi

        // EÄŸer bulduÄŸumuz benzerlik, ÅŸu ana kadarki en yÃ¼ksekten bÃ¼yÃ¼kse gÃ¼ncelle
        if (similarity > maxSimilarity) {
          maxSimilarity = similarity;
          bestMatchUser = userId;
        }
      }

      // DÃ¶ngÃ¼ bitti. En iyi eÅŸleÅŸme bizim limitimizi (Threshold) geÃ§ti mi?
      if (maxSimilarity > currentThreshold) {
        print("   âœ… EÅLEÅME BAÅARILI! TanÄ±nan: $bestMatchUser");
        return bestMatchUser;
      } else {
        print("   âŒ KÄ°MSE TANINAMADI. (En yÃ¼ksek benzerlik: $maxSimilarity)");
        return null; 
      }

    } catch (e) {
      print("TanÄ±ma hatasÄ±: $e");
      return null;
    }
  }

  /// 3. Yeni yÃ¼z kaydeder
  Future<void> registerFace({required String userId, required List<double> embedding}) async {
    // Koleksiyon ismini 'faces' olarak standartlaÅŸtÄ±rdÄ±k.
    await _firestore.collection('faces').doc(userId).set({
      'userId': userId,
      'embedding': embedding,
      'createdAt': FieldValue.serverTimestamp(),
    });
  }

  // Ã–klid Mesafesi HesaplayÄ±cÄ±
  // Bu fonksiyon iki yÃ¼z arasÄ±ndaki benzerliÄŸi -1 ile 1 arasÄ±nda hesaplar.
  double _cosineSimilarity(List<double> v1, List<double> v2) {
    double dotProduct = 0.0;
    double mag1 = 0.0;
    double mag2 = 0.0;

    for (int i = 0; i < v1.length; i++) {
      dotProduct += v1[i] * v2[i];
      mag1 += v1[i] * v1[i];
      mag2 += v2[i] * v2[i];
    }
    
    // SÄ±fÄ±ra bÃ¶lme hatasÄ±nÄ± Ã¶nlemek iÃ§in kontrol
    double magnitude = sqrt(mag1) * sqrt(mag2);
    if (magnitude == 0) return 0;

    return dotProduct / magnitude;
  }

  List<double> _l2Normalize(List<double> embedding) {
    double sum = 0;
    // 1. Karelerinin toplamÄ±nÄ± bul
    for (var x in embedding) {
      sum += x * x;
    }
    // 2. KarekÃ¶kÃ¼nÃ¼ al (BÃ¼yÃ¼klÃ¼k/Magnitude)
    double magnitude = sqrt(sum);

    // 3. Her sayÄ±yÄ± bÃ¼yÃ¼klÃ¼ÄŸe bÃ¶l
    return embedding.map((e) => e / magnitude).toList();
  }
}
